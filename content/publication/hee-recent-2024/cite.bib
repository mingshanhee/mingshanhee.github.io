@inproceedings{hee_recent_2024,
 abstract = {Moderating hate speech (HS) in the evolving online landscape is a complex challenge, compounded by the multimodal nature of digital content. This survey examines recent advancements in HS moderation, focusing on the burgeoning role of large language models (LLMs) and large multimodal models (LMMs) in detecting, explaining, debiasing, and countering HS. We begin with a comprehensive analysis of current literature, uncovering how text, images, and audio interact to spread HS. The combination of these modalities adds complexity and subtlety to HS dissemination. We also identified research gaps, particularly in underrepresented languages and cultures, and highlight the need for solutions in low-resource settings. The survey concludes with future research directions, including novel AI methodologies, ethical AI governance, and the development of context-aware systems. This overview aims to inspire further research and foster collaboration towards responsible and human-centric approaches to HS moderation in the digital age.},
 address = {Miami, Florida, USA},
 author = {Hee, Ming Shan and Sharma, Shivam and Cao, Rui and Nandi, Palash and Nakov, Preslav and Chakraborty, Tanmoy and Lee, Roy Ka-Wei},
 booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
 doi = {10.18653/v1/2024.findings-emnlp.254},
 editor = {Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung},
 file = {Full Text PDF:files/473/Hee et al. - 2024 - Recent Advances in Online Hate Speech Moderation Multimodality and the Role of Large Models.pdf:application/pdf},
 month = {November},
 pages = {4407--4419},
 publisher = {Association for Computational Linguistics},
 shorttitle = {Recent Advances in Online Hate Speech Moderation},
 title = {Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models},
 url = {https://aclanthology.org/2024.findings-emnlp.254/},
 urldate = {2025-03-03},
 year = {2024}
}
