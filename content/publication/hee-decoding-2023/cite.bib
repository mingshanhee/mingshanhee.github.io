@misc{hee_decoding_2023,
 abstract = {Recent studies have proposed models that yielded promising performance for the hateful meme classification task. Nevertheless, these proposed models do not generate interpretable explanations that uncover the underlying meaning and support the classification output. A major reason for the lack of explainable hateful meme methods is the absence of a hateful meme dataset that contains ground truth explanations for benchmarking or training. Intuitively, having such explanations can educate and assist content moderators in interpreting and removing flagged hateful memes. This paper address this research gap by introducing Hateful meme with Reasons Dataset (HatReD), which is a new multimodal hateful meme dataset annotated with the underlying hateful contextual reasons. We also define a new conditional generation task that aims to automatically generate underlying reasons to explain hateful memes and establish the baseline performance of state-of-the-art pre-trained language models on this task. We further demonstrate the usefulness of HatReD by analyzing the challenges of the new conditional generation task in explaining memes in seen and unseen domains. The dataset and benchmark models are made available here: https://github.com/Social-AI-Studio/HatRed},
 annote = {Comment: 9 pages. Accepted by IJCAI 2023},
 author = {Hee, Ming Shan and Chong, Wen-Haw and Lee, Roy Ka-Wei},
 doi = {10.48550/arXiv.2305.17678},
 file = {Preprint PDF:files/490/Hee et al. - 2023 - Decoding the Underlying Meaning of Multimodal Hateful Memes.pdf:application/pdf;Snapshot:files/491/2305.html:text/html},
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
 month = {June},
 note = {arXiv:2305.17678 [cs]},
 publisher = {arXiv},
 title = {Decoding the Underlying Meaning of Multimodal Hateful Memes},
 url = {http://arxiv.org/abs/2305.17678},
 urldate = {2025-03-03},
 year = {2023}
}
