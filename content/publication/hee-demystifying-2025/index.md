---
title: 'Demystifying Hateful Content: Leveraging Large Multimodal Models for Hateful
  Meme Detection with Explainable Decisions'
authors:
- Ming Shan Hee
- Roy Ka-Wei Lee
date: '2025-02-01'
publishDate: '2025-03-03T11:35:32.250424Z'
publication_types:
- manuscript
publication: '*arXiv*'
doi: 10.48550/arXiv.2502.11073
abstract: Hateful meme detection presents a significant challenge as a multimodal
  task due to the complexity of interpreting implicit hate messages and contextual
  cues within memes. Previous approaches have fine-tuned pre-trained vision-language
  models (PT-VLMs), leveraging the knowledge they gained during pre-training and their
  attention mechanisms to understand meme content. However, the reliance of these
  models on implicit knowledge and complex attention mechanisms renders their decisions
  difficult to explain, which is crucial for building trust in meme classification.
  In this paper, we introduce IntMeme, a novel framework that leverages Large Multimodal
  Models (LMMs) for hateful meme classification with explainable decisions. IntMeme
  addresses the dual challenges of improving both accuracy and explainability in meme
  moderation. The framework uses LMMs to generate human-like, interpretive analyses
  of memes, providing deeper insights into multimodal content and context. Additionally,
  it uses independent encoding modules for both memes and their interpretations, which
  are then combined to enhance classification performance. Our approach addresses
  the opacity and misclassification issues associated with PT-VLMs, optimizing the
  use of LMMs for hateful meme detection. We demonstrate the effectiveness of IntMeme
  through comprehensive experiments across three datasets, showcasing its superiority
  over state-of-the-art models.
tags:
- Computer Science - Computation and Language
links:
- name: URL
  url: http://arxiv.org/abs/2502.11073
---
